dataset:
  name: lama
  path: datasets/LAMA

plm:
  model_name: roberta
  model_path: roberta-large
  optimize:
    freeze_para: False
    lr: 0.00003
    weight_decay: 0.01
    scheduler:
      type: 
      num_warmup_steps: 500

train:
  batch_size: 8

test:
  batch_size: 8

dev:
  batch_size: 8



template: manual_template
verbalizer: 


manual_template:
  choice: 0
  file_path: scripts/LAMA/manual_template.txt
  
environment:
  num_gpus: 1
  cuda_visible_devices:
    - 7
  local_rank: 0 

learning_setting: full

